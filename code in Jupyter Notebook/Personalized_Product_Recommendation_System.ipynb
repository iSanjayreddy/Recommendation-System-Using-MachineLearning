{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flibbed3Rif-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flipkart Product Reccomendation - Recommendation Systems"
      ],
      "metadata": {
        "id": "g5OBfOzp1IT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Welcome to this presentation on building an advanced recommender system for e-commerce platforms. In this presentation, we'll delve into the various stages and techniques involved in creating a personalized recommendation engine to enhance user experiences."
      ],
      "metadata": {
        "id": "XE7xUYCtZE1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introdction"
      ],
      "metadata": {
        "id": "wq4DOI3JZZoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Our objective is to develop a recommender system that suggests products to users based on their historical interactions and product attributes. This involves analyzing user interactions, utilizing product information, implementing collaborative and content-based filtering techniques, and evaluating the system's performance."
      ],
      "metadata": {
        "id": "8zQVbQIlZcu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessin"
      ],
      "metadata": {
        "id": "jdvnezw11N2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We load the 'ratings.csv' dataset and examine its structure. Handling missing values and encoding categorical variables like gender and category into numerical representations, if needed, ensures our data is suitable for analysis"
      ],
      "metadata": {
        "id": "pWDNGbHdXABq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the ratings dataset\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset information:\")\n",
        "print(ratings_df.info())\n",
        "\n",
        "# Handle missing values (if any)\n",
        "if ratings_df.isnull().any().any():\n",
        "    ratings_df.dropna(inplace=True)\n",
        "    print(\"Missing values have been dropped.\")\n",
        "\n",
        "# Encode categorical variables like gender and category\n",
        "# Assuming 'gender' is a categorical variable that needs encoding\n",
        "gender_mapping = {'Male': 0, 'Female': 1}\n",
        "ratings_df['gender_encoded'] = ratings_df['gender'].map(gender_mapping)\n",
        "\n",
        "# Assuming 'category' is a categorical variable that needs encoding\n",
        "categories = ratings_df['category'].unique()\n",
        "category_mapping = {cat: idx for idx, cat in enumerate(categories)}\n",
        "ratings_df['category_encoded'] = ratings_df['category'].map(category_mapping)\n",
        "\n",
        "# Display the updated dataset\n",
        "print(\"\\nUpdated dataset:\")\n",
        "print(ratings_df.head())\n",
        "\n",
        "# Save the preprocessed dataset\n",
        "ratings_df.to_csv(\"preprocessed_ratings.csv\", index=False)\n",
        "print(\"\\nPreprocessed dataset saved as 'preprocessed_ratings.csv'\")\n"
      ],
      "metadata": {
        "id": "hg0a2HMp1qU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7e68f83c-dc18-4d29-c7c8-8b3429c88001"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2500 entries, 0 to 2499\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   user_id            2500 non-null   int64  \n",
            " 1   age                2500 non-null   int64  \n",
            " 2   gender             2500 non-null   object \n",
            " 3   interaction_score  2500 non-null   float64\n",
            " 4   product_id         2500 non-null   object \n",
            " 5   product_name       2500 non-null   object \n",
            " 6   category           2500 non-null   object \n",
            " 7   Image Link         2500 non-null   object \n",
            " 8   Rating             2500 non-null   int64  \n",
            "dtypes: float64(1), int64(3), object(5)\n",
            "memory usage: 175.9+ KB\n",
            "None\n",
            "\n",
            "Updated dataset:\n",
            "   user_id  age gender  interaction_score product_id  \\\n",
            "0     1480   32   Male           0.479977       WMPW   \n",
            "1     1480   32   Male           0.104574       TZMG   \n",
            "2     1480   32   Male           0.774475       RLXG   \n",
            "3     1480   32   Male           0.987237       EEUB   \n",
            "4     1480   32   Male           0.998097       JWPR   \n",
            "\n",
            "                            product_name  \\\n",
            "0    Alisha Solid Women's Cycling Shorts   \n",
            "1    FabHomeDecor Fabric Double Sofa Bed   \n",
            "2                             AW Bellies   \n",
            "3    Alisha Solid Women's Cycling Shorts   \n",
            "4  Sicons All Purpose Arnica Dog Shampoo   \n",
            "\n",
            "                                            category  \\\n",
            "0  [\"Clothing >> Women's Clothing >> Lingerie, Sl...   \n",
            "1  [\"Furniture >> Living Room Furniture >> Sofa B...   \n",
            "2  [\"Footwear >> Women's Footwear >> Ballerinas >...   \n",
            "3  [\"Clothing >> Women's Clothing >> Lingerie, Sl...   \n",
            "4  [\"Pet Supplies >> Grooming >> Skin & Coat Care...   \n",
            "\n",
            "                                          Image Link  Rating  gender_encoded  \\\n",
            "0  http://img5a.flixcart.com/image/short/u/4/a/al...       5               0   \n",
            "1  http://img6a.flixcart.com/image/sofa-bed/j/f/y...       3               0   \n",
            "2  http://img5a.flixcart.com/image/shoe/7/z/z/red...       5               0   \n",
            "3  http://img5a.flixcart.com/image/short/6/2/h/al...       4               0   \n",
            "4  http://img5a.flixcart.com/image/pet-shampoo/r/...       1               0   \n",
            "\n",
            "   category_encoded  \n",
            "0                 0  \n",
            "1                 1  \n",
            "2                 2  \n",
            "3                 0  \n",
            "4                 3  \n",
            "\n",
            "Preprocessed dataset saved as 'preprocessed_ratings.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqBg50_u1FMw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#user profiling"
      ],
      "metadata": {
        "id": "PqzMoXQhRpGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###User profiles are created by analyzing factors like age, gender, and past interactions. We incorporate user preferences, such as their preferred product categories. These profiles serve as the basis for personalized recommendations."
      ],
      "metadata": {
        "id": "i0e8a5ILXSR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Calculate average interaction score for each user\n",
        "user_avg_score = ratings_df.groupby(\"user_id\")[\"interaction_score\"].mean()\n",
        "\n",
        "# Calculate the number of interactions for each user\n",
        "user_interaction_count = ratings_df.groupby(\"user_id\")[\"interaction_score\"].count()\n",
        "\n",
        "# Calculate the average rating given by each user\n",
        "user_avg_rating = ratings_df.groupby(\"user_id\")[\"Rating\"].mean()\n",
        "\n",
        "# Combine user profiling features into a DataFrame\n",
        "user_profile = pd.DataFrame({\n",
        "    \"user_id\": user_avg_score.index,\n",
        "    \"avg_interaction_score\": user_avg_score,\n",
        "    \"interaction_count\": user_interaction_count,\n",
        "    \"avg_rating\": user_avg_rating\n",
        "})\n",
        "\n",
        "# Print the user profiles\n",
        "print(user_profile)\n",
        "\n",
        "# Example: Get the user profile for a specific user ID\n",
        "target_user_id = 1480\n",
        "target_user_profile = user_profile[user_profile[\"user_id\"] == target_user_id]\n",
        "\n",
        "print(\"\\nTarget User Profile:\")\n",
        "print(target_user_profile)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CEqM2GStRy4N",
        "outputId": "a4bf7561-1b63-4ebc-eb90-3a0130841a85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         user_id  avg_interaction_score  interaction_count  avg_rating\n",
            "user_id                                                               \n",
            "1000        1000               0.565311                 50        4.18\n",
            "1149        1149               0.466603                 50        3.88\n",
            "1426        1426               0.499101                 50        4.08\n",
            "1480        1480               0.535363                 50        4.00\n",
            "1995        1995               0.540730                 50        3.56\n",
            "2010        2010               0.464280                 50        4.16\n",
            "2114        2114               0.504821                 50        4.50\n",
            "2360        2360               0.446263                 50        4.74\n",
            "2374        2374               0.534615                 50        3.50\n",
            "2392        2392               0.467369                 50        3.96\n",
            "2502        2502               0.522899                 50        4.14\n",
            "2653        2653               0.517779                 50        4.60\n",
            "2656        2656               0.474778                 50        4.36\n",
            "2719        2719               0.449511                 50        4.42\n",
            "2735        2735               0.480909                 50        4.54\n",
            "3199        3199               0.526069                 50        4.52\n",
            "3294        3294               0.465401                 50        4.02\n",
            "3473        3473               0.542431                 50        4.36\n",
            "3497        3497               0.537674                 50        4.16\n",
            "3595        3595               0.472965                 50        4.24\n",
            "3842        3842               0.507912                 50        4.26\n",
            "3914        3914               0.514311                 50        4.14\n",
            "4190        4190               0.500389                 50        4.46\n",
            "4259        4259               0.468678                 50        3.48\n",
            "4380        4380               0.446994                 50        4.22\n",
            "4549        4549               0.492127                 50        2.82\n",
            "4633        4633               0.464995                 50        4.34\n",
            "5123        5123               0.568676                 50        4.38\n",
            "5529        5529               0.505220                 50        4.14\n",
            "5563        5563               0.422054                 50        4.76\n",
            "5933        5933               0.491956                 50        3.38\n",
            "6052        6052               0.551908                 50        4.68\n",
            "6196        6196               0.413974                 50        4.18\n",
            "6316        6316               0.508972                 50        4.04\n",
            "6592        6592               0.504150                 50        4.44\n",
            "6848        6848               0.522186                 50        4.60\n",
            "6883        6883               0.519656                 50        4.66\n",
            "7389        7389               0.524128                 50        4.64\n",
            "7470        7470               0.571977                 50        4.04\n",
            "7481        7481               0.473850                 50        3.70\n",
            "7536        7536               0.511688                 50        4.44\n",
            "7614        7614               0.495995                 50        4.52\n",
            "7699        7699               0.520566                 50        4.32\n",
            "8278        8278               0.509335                 50        4.30\n",
            "8544        8544               0.552827                 50        4.18\n",
            "8669        8669               0.503077                 50        3.66\n",
            "8774        8774               0.492736                 50        4.14\n",
            "9060        9060               0.474456                 50        3.50\n",
            "9530        9530               0.611449                 50        4.34\n",
            "9704        9704               0.570335                 50        4.54\n",
            "\n",
            "Target User Profile:\n",
            "         user_id  avg_interaction_score  interaction_count  avg_rating\n",
            "user_id                                                               \n",
            "1480        1480               0.535363                 50         4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#product Popularity"
      ],
      "metadata": {
        "id": "3SjcOtKqSErn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Product popularity scores can be based on interaction frequency or average ratings. We consider time decay factors to account for recency, ensuring our recommendations stay relevant."
      ],
      "metadata": {
        "id": "Ad4P_S-_XZkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "ratings_df = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# Calculate the total number of interactions for each product\n",
        "product_popularity = ratings_df.groupby(\"product_id\")[\"interaction_score\"].count()\n",
        "\n",
        "# Sort products by popularity in descending order\n",
        "sorted_popularity = product_popularity.sort_values(ascending=False)\n",
        "\n",
        "# Print the top 10 most popular products\n",
        "print(\"Top 10 Most Popular Products:\")\n",
        "print(sorted_popularity.head(10))\n",
        "\n",
        "# Example: Get the popularity for a specific product ID\n",
        "target_product_id = \"WMPW\"\n",
        "target_product_popularity = product_popularity.get(target_product_id, 0)\n",
        "\n",
        "print(\"\\nTarget Product Popularity:\")\n",
        "print(f\"Product ID: {target_product_id}\")\n",
        "print(f\"Popularity: {target_product_popularity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4GxKgZG2SHjx",
        "outputId": "dee1bf5d-651a-4b7a-8d90-7f98be0458e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Most Popular Products:\n",
            "product_id\n",
            "SCRX    2\n",
            "KQWO    2\n",
            "QHSD    2\n",
            "QSWI    2\n",
            "DWDF    2\n",
            "ONQV    2\n",
            "RKFC    1\n",
            "RQDB    1\n",
            "RNYG    1\n",
            "RODU    1\n",
            "Name: interaction_score, dtype: int64\n",
            "\n",
            "Target Product Popularity:\n",
            "Product ID: WMPW\n",
            "Popularity: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Collaborative filtering finds users similar to the target user and recommends products they haven't interacted with. This method leverages user behavior to generate meaningful recommendations."
      ],
      "metadata": {
        "id": "4O9es08oSLv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Content-based filtering utilizes product attributes like category, image, and description. By creating item profiles, we recommend products similar to those a user has shown interest in"
      ],
      "metadata": {
        "id": "MoTz09IgXnrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hybrid approaches strike a balance between both methods. By assigning appropriate weights, we optimize the recommendation process, enhancing user satisfaction"
      ],
      "metadata": {
        "id": "4UjWOr-oXtq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QlEs0ezISaNn",
        "outputId": "2df56e28-c64a-425c-fdcb-b570825ed04b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('ratings.csv')\n",
        "\n",
        "user_item_matrix = data.pivot(index='user_id', columns='product_id', values='interaction_score')\n",
        "user_item_matrix = user_item_matrix.fillna(0)\n",
        "\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "\n",
        "product_profile_matrix = data.pivot_table(index='product_id', columns='category', values='interaction_score', fill_value=0)\n",
        "\n",
        "def get_personalized_rankings(user_id, top_n=5):\n",
        "    if user_id not in user_item_matrix.index:\n",
        "        return []\n",
        "\n",
        "    user_index = user_item_matrix.index.get_loc(user_id)\n",
        "\n",
        "    # Collaborative Filtering: Calculate weighted scores based on user similarity\n",
        "    collaborative_scores = user_similarity[user_index] @ user_item_matrix.values\n",
        "    collaborative_ranking = list(user_item_matrix.columns[np.argsort(-collaborative_scores)])[:top_n]\n",
        "\n",
        "    # Content-Based Filtering: Calculate product scores based on product profile\n",
        "    content_scores = user_item_matrix.loc[user_id] @ product_profile_matrix.values\n",
        "    content_ranking = list(product_profile_matrix.index[np.argsort(-content_scores)])[:top_n]\n",
        "\n",
        "    # Hybrid Ranking: Combine collaborative and content-based rankings\n",
        "    hybrid_ranking = collaborative_ranking + [p for p in content_ranking if p not in collaborative_ranking]\n",
        "\n",
        "    return hybrid_ranking[:top_n]\n",
        "# Analyze all products and get top 10 products with ratings\n",
        "all_product_ids = user_item_matrix.columns\n",
        "product_ratings = []\n",
        "\n",
        "for product_id in all_product_ids:\n",
        "    product_name = data[data['product_id'] == product_id]['product_name'].values[0]\n",
        "    average_rating = user_item_matrix[product_id].mean()\n",
        "    product_ratings.append((product_id, product_name, average_rating))\n",
        "\n",
        "# Sort the products based on average ratings\n",
        "sorted_product_ratings = sorted(product_ratings, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "print(\"Top 10 Products with Ratings:\")\n",
        "for i, (product_id, product_name, average_rating) in enumerate(sorted_product_ratings[:10], start=1):\n",
        "    print(f\"{i}. {product_name} ({product_id}) - Average Rating: {average_rating:.2f}\")\n",
        "# Get personalized rankings for multiple users\n",
        "user_ids = [1480, 1995, 2719,3842, 2010]  # Example user IDs\n",
        "for user_id in user_ids:\n",
        "    personalized_rankings = get_personalized_rankings(user_id)\n",
        "    print(\"Personalized Rankings and Ratings for User\", user_id)\n",
        "    for i, product_id in enumerate(personalized_rankings, start=1):\n",
        "        product_name = data[data['product_id'] == product_id]['product_name'].values[0]\n",
        "        rating = user_item_matrix.loc[user_id, product_id]\n",
        "        print(f\"{i}. {product_name} ({product_id}) - Rating: {rating:.2f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FmoloJjISgmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Metrics"
      ],
      "metadata": {
        "id": "UUhsx77ES1Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We define metrics such as precision, recall, F1-score, and Mean Average Precision (MAP) to evaluate our recommendations. These metrics provide insights into how well our system performs"
      ],
      "metadata": {
        "id": "bEfOo_54XyaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Create a user-item interaction matrix\n",
        "user_item_matrix = pd.pivot_table(data, index='user_id', columns='product_id', values='interaction_score', fill_value=0)\n",
        "\n",
        "# Calculate user similarity matrix using cosine similarity\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "\n",
        "def get_personalized_rankings(user_id, top_n=5):\n",
        "    if user_id in data['user_id'].unique():\n",
        "        user_index = data['user_id'].unique().tolist().index(user_id)\n",
        "\n",
        "        # Collaborative Filtering: Calculate weighted scores based on user similarity\n",
        "        collaborative_scores = user_similarity[user_index] @ user_item_matrix.values\n",
        "        collaborative_ranking = list(user_item_matrix.columns[np.argsort(-collaborative_scores)])[:top_n]\n",
        "\n",
        "        return collaborative_ranking\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def evaluate_rankings(user_id, recommended_ranking, true_interactions, top_n=5):\n",
        "    recommended_products = recommended_ranking[:top_n]\n",
        "    true_positive = len(set(recommended_products) & set(true_interactions))\n",
        "\n",
        "    precision = true_positive / top_n\n",
        "    recall = true_positive / len(true_interactions)\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "# Evaluate rankings for each user\n",
        "user_ids = data['user_id'].unique()\n",
        "average_precision = 0\n",
        "average_recall = 0\n",
        "\n",
        "for user_id in user_ids:\n",
        "    user_data = data[data['user_id'] == user_id]\n",
        "    true_interactions = user_data[user_data['interaction_score'] >= 0.5]['product_id'].tolist()\n",
        "\n",
        "    personalized_ranking = get_personalized_rankings(user_id)\n",
        "    precision, recall = evaluate_rankings(user_id, personalized_ranking, true_interactions)\n",
        "\n",
        "    average_precision += precision\n",
        "    average_recall += recall\n",
        "\n",
        "# Calculate average precision and recall across all users\n",
        "average_precision /= len(user_ids)\n",
        "average_recall /= len(user_ids)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = 2 * (average_precision * average_recall) / (average_precision + average_recall)\n",
        "\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"F1-score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ak-BMspfS3yr",
        "outputId": "60bd2bf7-fe20-4912-c45d-8ed8165a911a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision: 0.02\n",
            "Average Recall: 0.005\n",
            "F1-score: 0.008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Algorithm Evaluation"
      ],
      "metadata": {
        "id": "jot09rboTNKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We split the dataset into training and testing sets, employing techniques like cross-validation to fine-tune our algorithm's parameters. This step assures us of the system's effectiveness.\n",
        "\n",
        "###Using SVD, we can determine the rank of the matrix, quantify the sensitivity of a linear system to numerical error, or obtain an optimal lower-rank approximation to the matrix"
      ],
      "metadata": {
        "id": "KGhBBB7bX95d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.accuracy import rmse\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Load data into Surprise's Dataset format\n",
        "reader = Reader(rating_scale=(0, 1))\n",
        "data = Dataset.load_from_df(data[['user_id', 'product_id', 'interaction_score']], reader)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiate SVD model\n",
        "model = SVD(n_factors=100, n_epochs=20, random_state=42)\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(trainset)\n",
        "\n",
        "# Predict ratings on the test set\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_score = rmse(predictions)\n",
        "accuracy_percentage = (1 - rmse_score) * 100  # Calculate accuracy in percentage\n",
        "\n",
        "# print(\"Root Mean Squared Error (RMSE):\", rmse_score)\n",
        "print(\"Accuracy Percentage:\", accuracy_percentage)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Bmo8QN6eTLwe",
        "outputId": "badad4bb-12ef-4155-cba4-72529686aacc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.2929\n",
            "Accuracy Percentage: 70.71198763900101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To conclude, building an effective recommender system involves a holistic approach, encompassing data preprocessing, user profiling, collaborative and content-based filtering, hybrid techniques, thorough evaluation, and personalized rankings.\n",
        "\n",
        "##By carefully crafting each step, we create a recommendation engine that enhances user engagement and satisfaction, ultimately driving the success of e-commerce platforms.\n",
        "\n",
        "##Thank you for joining this presentation on building an advanced recommender system for e-commerce. We hope you now have a clearer understanding of the intricacies involved in creating personalized recommendations. Feel free to reach out with any questions"
      ],
      "metadata": {
        "id": "-G9YQcXhYfEz"
      }
    }
  ]
}